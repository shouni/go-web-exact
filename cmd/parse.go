package cmd

import (
	"context"
	"fmt"
	"log"
	"time"

	"github.com/mmcdole/gofeed"
	"github.com/shouni/go-http-kit/pkg/httpkit"
	"github.com/spf13/cobra"

	// ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨˜æ†¶ã«ã‚ã‚‹ package feed (parser.go) ã‚’åˆ©ç”¨ã—ã¾ã™
	"go-web-exact/pkg/feed"
)

// ãƒ•ã‚£ãƒ¼ãƒ‰URLã‚’ä¿æŒã™ã‚‹ãƒ•ãƒ©ã‚°å¤‰æ•°
var feedURL string

// ãƒ•ã‚£ãƒ¼ãƒ‰ã®å…¨ä½“å‡¦ç†ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š (extractCmdã¨çµ±ä¸€)
const overallFeedTimeoutFactor = 2 // ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®2å€

// runParsePipeline ã¯ã€ãƒ•ã‚£ãƒ¼ãƒ‰ã®å–å¾—ã¨ãƒ‘ãƒ¼ã‚¹ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã§ã™ã€‚
func runParsePipeline(url string, parser *feed.Parser, overallTimeout time.Duration) (*gofeed.Feed, error) {
	// 1. å…¨ä½“å‡¦ç†ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š
	ctx, cancel := context.WithTimeout(context.Background(), overallTimeout)
	defer cancel()

	// 2. æŠ½å‡ºã®å®Ÿè¡Œ
	parsedFeed, err := parser.FetchAndParse(ctx, url)
	if err != nil {
		// ã‚¨ãƒ©ãƒ¼ã®ãƒ©ãƒƒãƒ”ãƒ³ã‚°
		return nil, fmt.Errorf("ãƒ•ã‚£ãƒ¼ãƒ‰ã®å–å¾—ãŠã‚ˆã³ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ (URL: %s): %w", url, err)
	}

	return parsedFeed, nil
}

var parseCmd = &cobra.Command{
	Use:   "parse",
	Short: "RSS/Atomãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—ãƒ»è§£æã—ã€ã‚¿ã‚¤ãƒˆãƒ«ã¨è¨˜äº‹ã‚’ä¸€è¦§è¡¨ç¤ºã—ã¾ã™",
	Long:  `æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰RSSã¾ãŸã¯Atomãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã€ãã®å†…å®¹ï¼ˆãƒ•ã‚£ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒˆãƒ«ã€è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã€URLï¼‰ã‚’æ•´å½¢ã—ã¦è¡¨ç¤ºã—ã¾ã™ã€‚`,

	// ğŸ’¡ ä¿®æ­£ç‚¹: ä½ç½®å¼•æ•°ã‚’ç¦æ­¢ã™ã‚‹è¨­å®šã‚’è¿½åŠ  (ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ©ãƒ¼ã®è§£æ±º)
	Args: cobra.NoArgs,

	RunE: func(cmd *cobra.Command, args []string) error {

		// Flags.TimeoutSec ã¯ cmd/root.go ã§å®šç¾©ã•ã‚Œã¦ã„ã¾ã™
		// å…¨ä½“ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¨­å®š: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®2å€ (extractCmdã¨çµ±ä¸€)
		overallTimeout := time.Duration(Flags.TimeoutSec*overallFeedTimeoutFactor) * time.Second
		if Flags.TimeoutSec == 0 {
			// extractCmdã®å®šæ•°ã‚’æµç”¨
			overallTimeout = defaultOverallTimeoutIfClientTimeoutIsZero
		}

		log.Printf("å‡¦ç†å¯¾è±¡ãƒ•ã‚£ãƒ¼ãƒ‰URL: %s (å…¨ä½“ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: %s)\n", feedURL, overallTimeout)

		// 1. ä¾å­˜æ€§ã®åˆæœŸåŒ–
		// cmd/root.go ã§åˆæœŸåŒ–ã•ã‚ŒãŸå…±æœ‰ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ã‚’ä½¿ç”¨
		fetcher := GetGlobalFetcher()
		if fetcher == nil {
			return fmt.Errorf("HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚rootã‚³ãƒãƒ³ãƒ‰ã®PreRunã‚’ç¢ºèªã—ã¦ãã ã•ã„")
		}

		// Fetcherã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ *httpkit.Client ã®å®Ÿè£…ã«ãƒ€ã‚¦ãƒ³ã‚­ãƒ£ã‚¹ãƒˆã—ã¾ã™ã€‚
		// NewParserãŒ *httpkit.Client ã‚’å—ã‘å–ã‚‹ãŸã‚ã€‚
		client, ok := fetcher.(*httpkit.Client)
		if !ok {
			return fmt.Errorf("äºˆæœŸã—ãªã„ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ã®å®Ÿè£…ã§ã™: %T", fetcher)
		}

		// ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨˜æ†¶ã«ã‚ã‚‹ package feed ã® NewParser ã‚’åˆ©ç”¨
		parser := feed.NewParser(client)

		// 2. ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè¡Œ
		parsedFeed, err := runParsePipeline(feedURL, parser, overallTimeout)
		if err != nil {
			return fmt.Errorf("ãƒ•ã‚£ãƒ¼ãƒ‰è§£æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: %w", err)
		}

		// 3. çµæœã®å‡ºåŠ›
		fmt.Printf("--- ãƒ•ã‚£ãƒ¼ãƒ‰è§£æçµæœ ---\n")
		fmt.Printf("ãƒ•ã‚£ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒˆãƒ«: %s\n", parsedFeed.Title)
		if parsedFeed.Link != "" {
			fmt.Printf("ãƒªãƒ³ã‚¯: %s\n", parsedFeed.Link)
		}
		fmt.Printf("åˆè¨ˆè¨˜äº‹æ•°: %d\n", len(parsedFeed.Items))
		fmt.Println("-----------------------")

		for i, item := range parsedFeed.Items {
			fmt.Printf("[%d] %s\n", i+1, item.Title)
			fmt.Printf("    URL: %s\n", item.Link)
			if item.PublishedParsed != nil {
				fmt.Printf("    å…¬é–‹æ—¥: %s\n", item.PublishedParsed.Local().Format("2006-01-02 15:04:05"))
			}
		}

		return nil
	},
}

func init() {
	// ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰å›ºæœ‰ã®ãƒ•ãƒ©ã‚°å®šç¾©
	parseCmd.Flags().StringVarP(&feedURL, "url", "u", "", "è§£æå¯¾è±¡ã®ãƒ•ã‚£ãƒ¼ãƒ‰ (RSS/Atom) URL")

	// URLãƒ•ãƒ©ã‚°ã‚’å¿…é ˆã«ã™ã‚‹
	parseCmd.MarkFlagRequired("url")
}
