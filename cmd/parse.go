package cmd

import (
	"context"
	"fmt"
	"log"
	"time"

	"github.com/shouni/go-web-exact/v2/pkg/feed"
	"github.com/spf13/cobra"
)

// ãƒ•ã‚£ãƒ¼ãƒ‰è§£æã®å…¨ä½“å‡¦ç†ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¿‚æ•°
const overallFeedTimeoutFactor = 2

// ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ•ãƒ©ã‚°å¤‰æ•°
var (
	feedURL string // -u, --url ãƒ•ãƒ©ã‚°ã§å—ã‘å–ã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰URL
)

// runParsePipeline ã¯ãƒ•ã‚£ãƒ¼ãƒ‰ã®å–å¾—ã¨è§£æã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã§ã™ã€‚
func runParsePipeline(feedURL string, fetcher feed.Fetcher) error {

	// 1. å…¨ä½“ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®è¨­å®š
	clientTimeout := time.Duration(Flags.TimeoutSec) * time.Second
	if Flags.TimeoutSec == 0 {
		clientTimeout = defaultTimeoutSec * time.Second
	}
	overallTimeout := clientTimeout * overallFeedTimeoutFactor

	// 2. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®è¨­å®š
	ctx, cancel := context.WithTimeout(context.Background(), overallTimeout)
	defer cancel()

	log.Printf("ãƒ•ã‚£ãƒ¼ãƒ‰è§£æé–‹å§‹ (URL: %s, å…¨ä½“ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: %s)\n", feedURL, overallTimeout)

	// 3. ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ‘ãƒ¼ã‚µãƒ¼ã®åˆæœŸåŒ–
	parser := feed.NewParser(fetcher)

	// 4. ãƒ•ã‚£ãƒ¼ãƒ‰ã®å–å¾—ã¨ãƒ‘ãƒ¼ã‚¹ã‚’å®Ÿè¡Œ
	rssFeed, err := parser.FetchAndParse(ctx, feedURL)
	if err != nil {
		return fmt.Errorf("ãƒ•ã‚£ãƒ¼ãƒ‰ã®ãƒ‘ãƒ¼ã‚¹å¤±æ•—: %w", err)
	}

	// 5. çµæœã®å‡ºåŠ›
	fmt.Printf("\n--- ãƒ•ã‚£ãƒ¼ãƒ‰è§£æçµæœ ---\n")
	fmt.Printf("ã‚¿ã‚¤ãƒˆãƒ«: %s\n", rssFeed.Title)
	fmt.Printf("URL: %s\n", rssFeed.Link)

	// ğŸ’¡ ä¿®æ­£: UpdatedParsed ãŒ nil ã§ãªã„ã‹ãƒã‚§ãƒƒã‚¯ (ãƒ‘ãƒ‹ãƒƒã‚¯å¯¾ç­–)
	if rssFeed.UpdatedParsed != nil {
		fmt.Printf("æ›´æ–°æ—¥æ™‚: %s\n", rssFeed.UpdatedParsed.Local().Format("2006/01/02 15:04:05"))
	} else {
		// æ›´æ–°æ—¥æ™‚ãŒãªã„å ´åˆã¯ãã®æ—¨ã‚’å‡ºåŠ›
		fmt.Printf("æ›´æ–°æ—¥æ™‚: (æƒ…å ±ãªã—)\n")
	}

	fmt.Printf("è¨˜äº‹æ•°: %d\n", len(rssFeed.Items))
	fmt.Println("----------------------")

	// è¨˜äº‹ãƒªã‚¹ãƒˆã®è¡¨ç¤º
	for i, item := range rssFeed.Items {
		fmt.Printf("[%d] %s\n", i+1, item.Title)
		fmt.Printf("    - ãƒªãƒ³ã‚¯: %s\n", item.Link)

		// ğŸ’¡ è¨˜äº‹ã®å…¬é–‹æ—¥æ™‚ã‚‚ nil ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ ã—ã€å …ç‰¢æ€§ã‚’å‘ä¸Š
		if item.PublishedParsed != nil {
			fmt.Printf("    - å…¬é–‹: %s\n", item.PublishedParsed.Local().Format("2006/01/02 15:04:05"))
		}
	}
	fmt.Println("----------------------")

	return nil
}

var parseCmd = &cobra.Command{
	Use:   "parse",
	Short: "RSS/Atomãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—ãƒ»è§£æã—ã€ã‚¿ã‚¤ãƒˆãƒ«ã¨è¨˜äº‹ã‚’ä¸€è¦§è¡¨ç¤ºã—ã¾ã™",
	Long:  `æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰URLã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã—ã€ãƒ•ã‚£ãƒ¼ãƒ‰ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚„è¨˜äº‹ã®ãƒªãƒ³ã‚¯ãªã©ã‚’æ¨™æº–å‡ºåŠ›ã«å‡ºåŠ›ã—ã¾ã™ã€‚`,
	Args:  cobra.NoArgs,

	RunE: func(cmd *cobra.Command, args []string) error {

		// 1. ä¾å­˜æ€§ã®åˆæœŸåŒ– (Fetcher)
		fetcher := GetGlobalFetcher()
		if fetcher == nil {
			return fmt.Errorf("HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
		}

		// 2. URLã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã‚¹ã‚­ãƒ¼ãƒ è£œå®Œ
		if feedURL == "" {
			return fmt.Errorf("ãƒ•ã‚£ãƒ¼ãƒ‰URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„ (--urlã¾ãŸã¯-u)")
		}

		processedURL, err := ensureScheme(feedURL)
		if err != nil {
			return fmt.Errorf("URLã‚¹ã‚­ãƒ¼ãƒ ã®å‡¦ç†ã‚¨ãƒ©ãƒ¼: %w", err)
		}

		// 3. ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè¡Œ
		return runParsePipeline(processedURL, fetcher)
	},
}

func init() {
	// -u, --url ãƒ•ãƒ©ã‚°ã®å®šç¾©
	parseCmd.Flags().StringVarP(&feedURL, "url", "u", "", "è§£æå¯¾è±¡ã®ãƒ•ã‚£ãƒ¼ãƒ‰URL (RSS/Atom)")
	parseCmd.MarkFlagRequired("url")
}
