package cmd

import (
	"bufio"
	"context"
	"fmt"
	"log"
	"net/url"
	"os"
	"time"

	"github.com/shouni/go-web-exact/v2/pkg/extract"
	"github.com/spf13/cobra"
)

// ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ•ãƒ©ã‚°å¤‰æ•°ã‚’å®šç¾©
var rawUrl string

// NOTE: ä»¥å‰ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚ã£ãŸå®šæ•° defaultOverallTimeoutIfClientTimeoutIsZero ã¯å‰Šé™¤ã•ã‚Œã¾ã—ãŸã€‚
// ä»£ã‚ã‚Šã«ã€cmd/root.go ã§å®šç¾©ã•ã‚ŒãŸ DefaultOverallTimeout ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

// runExtractionPipeline ã¯ã€Webã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æŠ½å‡ºã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã§ã™ã€‚
func runExtractionPipeline(rawURL string, extractor *extract.Extractor, overallTimeout time.Duration) (text string, isBodyExtracted bool, err error) {
	// 1. å…¨ä½“å‡¦ç†ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š
	ctx, cancel := context.WithTimeout(context.Background(), overallTimeout)
	defer cancel()

	// 2. æŠ½å‡ºã®å®Ÿè¡Œ
	text, isBodyExtracted, err = extractor.FetchAndExtractText(ctx, rawURL)
	if err != nil {
		// ã‚¨ãƒ©ãƒ¼ã®ãƒ©ãƒƒãƒ”ãƒ³ã‚°
		return "", false, fmt.Errorf("ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºã‚¨ãƒ©ãƒ¼ (URL: %s): %w", rawURL, err)
	}

	return text, isBodyExtracted, nil
}

// ensureScheme ã¯ã€URLã®ã‚¹ã‚­ãƒ¼ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã« https:// ã‚’è£œå®Œã—ã¾ã™ã€‚
func ensureScheme(rawURL string) (string, error) {
	// 1. ã¾ãšç¾åœ¨ã®URLã‚’ãƒ‘ãƒ¼ã‚¹
	parsedURL, err := url.Parse(rawURL)
	if err != nil {
		return "", fmt.Errorf("URLã®ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: %w", err)
	}

	// 2. ã‚¹ã‚­ãƒ¼ãƒ ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã®ãƒã‚§ãƒƒã‚¯
	if parsedURL.Scheme != "" {
		if parsedURL.Scheme != "http" && parsedURL.Scheme != "https" {
			return "", fmt.Errorf("ç„¡åŠ¹ãªURLã‚¹ã‚­ãƒ¼ãƒ ã§ã™ã€‚httpã¾ãŸã¯httpsã‚’æŒ‡å®šã—ã¦ãã ã•ã„: %s", rawURL)
		}
		// æ—¢å­˜ã®ã‚¹ã‚­ãƒ¼ãƒ ã‚’å°Šé‡
		return rawURL, nil
	}

	// 3. ã‚¹ã‚­ãƒ¼ãƒ ãŒãªã„å ´åˆã€HTTPSã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã¦ä»˜ä¸
	return "https://" + rawURL, nil
}

// ğŸ’¡ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«é–¢ã™ã‚‹æŒ‡æ‘˜: DIã‚’æ¨å¥¨ã€‚GetGlobalFetcher()ã¸ã®ä¾å­˜ã¯ãƒ†ã‚¹ãƒˆå®¹æ˜“æ€§ã‚’ä½ä¸‹ã•ã›ã‚‹ã€‚
var extractorcmd = &cobra.Command{
	Use:   "extract",
	Short: "æŒ‡å®šã•ã‚ŒãŸURLã¾ãŸã¯æ¨™æº–å…¥åŠ›ã‹ã‚‰Webã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™",
	Long:  `æŒ‡å®šã•ã‚ŒãŸURLã¾ãŸã¯æ¨™æº–å…¥åŠ›ã‹ã‚‰Webã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚`,

	// ä½ç½®å¼•æ•°ã¯å–ã‚‰ãªã„è¨­å®š
	Args: cobra.NoArgs,

	RunE: func(cmd *cobra.Command, args []string) error {

		// overallTimeout ã®è¨­å®š: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (Flags.TimeoutSec) ã®2å€ã‚’å…¨ä½“ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¨ã—ã¾ã™ã€‚
		// ğŸ’¡ ä¿®æ­£ç‚¹1: intã®ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’é˜²ããŸã‚ã€time.Durationã«ã‚­ãƒ£ã‚¹ãƒˆã—ã¦ã‹ã‚‰ä¹—ç®—ã™ã‚‹
		overallTimeout := time.Duration(Flags.TimeoutSec) * 2 * time.Second
		if Flags.TimeoutSec == 0 {
			// ğŸ’¡ ä¿®æ­£ç‚¹2: æ–°ã—ã„ã‚°ãƒ­ãƒ¼ãƒãƒ«å®šæ•° DefaultOverallTimeout ã‚’å‚ç…§ã™ã‚‹
			overallTimeout = DefaultOverallTimeout
		}

		// 1. å‡¦ç†å¯¾è±¡URLã®æ±ºå®š (ãƒ•ãƒ©ã‚°å„ªå…ˆ)
		urlToProcess := rawUrl
		if urlToProcess == "" {
			log.Println("URLãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€æ¨™æº–å…¥åŠ›ã‹ã‚‰URLã‚’èª­ã¿è¾¼ã¿ã¾ã™...")
			scanner := bufio.NewScanner(os.Stdin)
			fmt.Print("å‡¦ç†ã™ã‚‹URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ")

			if !scanner.Scan() {
				if err := scanner.Err(); err != nil {
					return fmt.Errorf("æ¨™æº–å…¥åŠ›ã®èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: %w", err)
				}
				return fmt.Errorf("URLãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“")
			}
			urlToProcess = scanner.Text()
		}

		// 2. URLã®ã‚¹ã‚­ãƒ¼ãƒ è£œå®Œã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
		processedURL, err := ensureScheme(urlToProcess)
		if err != nil {
			return fmt.Errorf("URLã‚¹ã‚­ãƒ¼ãƒ ã®å‡¦ç†ã‚¨ãƒ©ãƒ¼: %w", err)
		}
		log.Printf("å‡¦ç†å¯¾è±¡URL: %s (å…¨ä½“ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: %s)\n", processedURL, overallTimeout)

		// 3. ä¾å­˜æ€§ã®åˆæœŸåŒ–
		// cmd/root.go ã§åˆæœŸåŒ–ã•ã‚ŒãŸå…±æœ‰ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ã‚’ä½¿ç”¨ã€‚
		fetcher := GetGlobalFetcher()
		if fetcher == nil {
			// ğŸ’¡ ä¿®æ­£ç‚¹3: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ½è±¡åŒ–
			return fmt.Errorf("HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
		}

		// ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨˜æ†¶ã«ã‚ã‚‹ extract ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã® NewExtractor ã‚’åˆ©ç”¨
		extractor, err := extract.NewExtractor(fetcher)
		if err != nil {
			return fmt.Errorf("Extractorã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: %w", err)
		}

		// 4. ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè¡Œ
		text, isBodyExtracted, err := runExtractionPipeline(processedURL, extractor, overallTimeout)
		if err != nil {
			// ğŸ’¡ ä¿®æ­£ç‚¹4: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã« processedURL æƒ…å ±ã‚’å«ã‚ã‚‹
			return fmt.Errorf("ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ (URL: %s): %w", processedURL, err)
		}

		// 5. çµæœã®å‡ºåŠ›
		if !isBodyExtracted {
			fmt.Printf("æœ¬æ–‡ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸãŒã€ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—ã—ã¾ã—ãŸ:\n%s\n", text)
		} else {
			fmt.Println("--- æŠ½å‡ºã•ã‚ŒãŸæœ¬æ–‡ ---")
			fmt.Println(text)
			fmt.Println("-----------------------")
		}

		return nil
	},
}

func init() {
	extractorcmd.Flags().StringVarP(&rawUrl, "url", "u", "", "æŠ½å‡ºå¯¾è±¡ã®URL")
}
