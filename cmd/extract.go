package cmd

import (
	"bufio"
	"context"
	"fmt"
	"log"
	"net/url"
	"os"
	"time"

	"github.com/shouni/go-web-exact/v2/pkg/extract"
	"github.com/spf13/cobra"
)

var rawUrl string

// runExtractionPipeline ã¯ã€Webã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æŠ½å‡ºã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã§ã™ã€‚
// Goã®æ…£ç¿’ã«å¾“ã„ã€ã‚¨ãƒ©ãƒ¼ã‚’æœ€å¾Œã®æˆ»ã‚Šå€¤ã«ã—ã¾ã™ã€‚
func runExtractionPipeline(rawURL string, extractor *extract.Extractor, overallTimeout time.Duration) (text string, isBodyExtracted bool, err error) {
	// 1. å…¨ä½“å‡¦ç†ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š
	// ğŸ’¡ overallTimeout ã¯ã€URLãƒ‘ãƒ¼ã‚¹ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å‡¦ç†ï¼ˆãƒªãƒˆãƒ©ã‚¤å«ã‚€ï¼‰ã€HTMLãƒ‘ãƒ¼ã‚¹å…¨ä½“ã‚’ã‚«ãƒãƒ¼ã™ã‚‹æ™‚é–“
	ctx, cancel := context.WithTimeout(context.Background(), overallTimeout)
	defer cancel()

	// 2. æŠ½å‡ºã®å®Ÿè¡Œ
	// Contextä»˜ãã§ extractor.FetchAndExtractText ã‚’å‘¼ã³å‡ºã—ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ä¼æ’­ã•ã›ã‚‹
	text, isBodyExtracted, err = extractor.FetchAndExtractText(ctx, rawURL)
	if err != nil {
		// ã‚¨ãƒ©ãƒ¼ã®ãƒ©ãƒƒãƒ”ãƒ³ã‚°
		return "", false, fmt.Errorf("ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºã‚¨ãƒ©ãƒ¼ (URL: %s): %w", rawURL, err)
	}

	return text, isBodyExtracted, nil
}

// ensureScheme ã¯ã€URLã®ã‚¹ã‚­ãƒ¼ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã« https:// ã¾ãŸã¯ http:// ã‚’è£œå®Œã—ã¾ã™ã€‚
// ã‚¹ã‚­ãƒ¼ãƒ ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ã€ãã‚ŒãŒ http ã¾ãŸã¯ https ã§ã‚ã‚‹ã‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚
func ensureScheme(rawURL string) (string, error) {
	// 1. ã¾ãšç¾åœ¨ã®URLã‚’ãƒ‘ãƒ¼ã‚¹
	parsedURL, err := url.Parse(rawURL)
	if err != nil {
		return "", fmt.Errorf("URLã®ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: %w", err)
	}

	// 2. ã‚¹ã‚­ãƒ¼ãƒ ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã®ãƒã‚§ãƒƒã‚¯
	if parsedURL.Scheme != "" {
		if parsedURL.Scheme != "http" && parsedURL.Scheme != "https" {
			return "", fmt.Errorf("ç„¡åŠ¹ãªURLã‚¹ã‚­ãƒ¼ãƒ ã§ã™ã€‚httpã¾ãŸã¯httpsã‚’æŒ‡å®šã—ã¦ãã ã•ã„: %s", rawURL)
		}
		return rawURL, nil
	}

	// 3. ã‚¹ã‚­ãƒ¼ãƒ ãŒãªã„å ´åˆã€HTTPSã‚’å„ªå…ˆçš„ã«è©¦ã™
	return "https://" + rawURL, nil
}

var extractCmd = &cobra.Command{
	Use:   "extract [URL]",
	Short: "æŒ‡å®šã•ã‚ŒãŸURLã¾ãŸã¯æ¨™æº–å…¥åŠ›ã‹ã‚‰Webã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™",
	Long:  `æŒ‡å®šã•ã‚ŒãŸURLã¾ãŸã¯æ¨™æº–å…¥åŠ›ã‹ã‚‰Webã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚`,
	RunE: func(cmd *cobra.Command, args []string) error {

		// ğŸ’¡ ä¿®æ­£ç‚¹1: clientTimeout (30ç§’) ã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤ã€‚
		// HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¯ GetGlobalFetcher() ã‹ã‚‰å–å¾—ã•ã‚Œã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒä¿æŒã—ã¾ã™ã€‚

		// ğŸ’¡ overallTimeout ã®è¨­å®š: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¨ã¯åˆ¥ã«ã€æŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¨­å®šã—ã¾ã™ã€‚
		// ã“ã“ã§ã¯ã€root.goã§è¨­å®šã•ã‚ŒãŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (Flags.TimeoutSec) ã®2å€ã‚’å…¨ä½“ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¨ã—ã¾ã™ã€‚
		// ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ `time.Duration` ã«å¤‰æ›ã—ã¾ã™ã€‚
		overallTimeout := time.Duration(Flags.TimeoutSec) * 2 * time.Second
		if Flags.TimeoutSec == 0 {
			// 0ç§’ãŒè¨­å®šã•ã‚ŒãŸå ´åˆã®é˜²å¾¡çš„ãªè¨­å®š
			overallTimeout = 20 * time.Second
		}

		// 1. å‡¦ç†å¯¾è±¡URLã®æ±ºå®š (ãƒ•ãƒ©ã‚°å„ªå…ˆ)
		urlToProcess := rawUrl
		if urlToProcess == "" {
			log.Println("URLãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€æ¨™æº–å…¥åŠ›ã‹ã‚‰URLã‚’èª­ã¿è¾¼ã¿ã¾ã™...")
			scanner := bufio.NewScanner(os.Stdin)
			fmt.Print("å‡¦ç†ã™ã‚‹URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ")

			if !scanner.Scan() {
				if err := scanner.Err(); err != nil {
					return fmt.Errorf("æ¨™æº–å…¥åŠ›ã®èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: %w", err)
				}
				return fmt.Errorf("URLãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“")
			}
			urlToProcess = scanner.Text()
		}

		// 2. URLã®ã‚¹ã‚­ãƒ¼ãƒ è£œå®Œã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ (ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã«åˆ†é›¢)
		processedURL, err := ensureScheme(urlToProcess)
		if err != nil {
			return fmt.Errorf("URLã‚¹ã‚­ãƒ¼ãƒ ã®å‡¦ç†ã‚¨ãƒ©ãƒ¼: %w", err)
		}
		log.Printf("å‡¦ç†å¯¾è±¡URL: %s (å…¨ä½“ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: %s)\n", processedURL, overallTimeout)

		// 3. ä¾å­˜æ€§ã®åˆæœŸåŒ– (DIã‚³ãƒ³ãƒ†ãƒŠã®å½¹å‰²)
		// ğŸ’¡ ä¿®æ­£ç‚¹2: cmd/root.go ã§åˆæœŸåŒ–ã•ã‚ŒãŸå…±æœ‰ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ã‚’ä½¿ç”¨ã€‚
		// ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã® --timeout ãŒåæ˜ ã•ã‚Œã¾ã™ã€‚
		fetcher := GetGlobalFetcher()
		if fetcher == nil {
			// GetGlobalFetcherãŒnilã‚’è¿”ã™ã“ã¨ã¯é€šå¸¸ã‚ã‚Šã¾ã›ã‚“ãŒã€å¿µã®ãŸã‚ãƒã‚§ãƒƒã‚¯
			return fmt.Errorf("HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚rootã‚³ãƒãƒ³ãƒ‰ã®PreRunã‚’ç¢ºèªã—ã¦ãã ã•ã„")
		}

		// ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨˜æ†¶ã«ã‚ã‚‹ extract ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã® NewExtractor ã‚’åˆ©ç”¨
		extractor, err := extract.NewExtractor(fetcher)
		if err != nil {
			return fmt.Errorf("Extractorã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: %w", err)
		}

		// 4. ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã®å®Ÿè¡Œ (ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’å‘¼ã³å‡ºã—)
		text, isBodyExtracted, err := runExtractionPipeline(processedURL, extractor, overallTimeout)
		if err != nil {
			return fmt.Errorf("ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: %w", err)
		}

		// 5. çµæœã®å‡ºåŠ›
		if !isBodyExtracted {
			fmt.Printf("æœ¬æ–‡ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸãŒã€ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—ã—ã¾ã—ãŸ:\n%s\n", text)
		} else {
			fmt.Println("--- æŠ½å‡ºã•ã‚ŒãŸæœ¬æ–‡ ---")
			fmt.Println(text)
			fmt.Println("-----------------------")
		}

		return nil
	},
}

func init() {
	// rawUrl å¤‰æ•°ã«ãƒ•ãƒ©ã‚°ã®ãƒã‚¤ãƒ³ã‚¿ã‚’ãƒã‚¤ãƒ³ãƒ‰ã—ã¾ã™
	extractCmd.Flags().StringVarP(&rawUrl, "url", "u", "", "æŠ½å‡ºå¯¾è±¡ã®URL")
}
